{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f72e6b-d56b-4f59-9684-1b8d1539d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5be3a-773a-40dc-abc3-fbae6659de9d",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033551f2-c4d1-4a15-b2ee-99a18a38bd91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963703fc71bd4b1b871db8cdfbf783e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19869c19c08a4742bfae6f20c252545a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5a44d9587c416ebf221f7c1ebd6c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b394d003f3754937bcb3e82d2a782983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6df077d87ab4872a226ddd039f8ab15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa5be8a10094bdebc60104dab559968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1add8d2cb3243ca8cd283b8d13b628b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3063b989def34a2382d1647e546a3aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568a454803c5446e937db77863a7b99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"papluca/language-identification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34219cd-f52b-401f-826d-4e7d8ce811cb",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e93821d-11e9-4ae4-8c4e-9285ff849f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 70000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd27d05-aa8c-4072-935d-f75db7445c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 'zh', 'text': '如果自己家用，建议买7mm的，这个11mm的出胶太快太多了'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7102843e-0e74-4e67-9205-a2be89c6bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 'nl', 'text': 'Een man speelt gitaar.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541f445d-6f9d-4402-8d9a-6ac92d395a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 'nl',\n",
       " 'text': 'Voormalig Pakistaans president Pervez Musharraf weer gearresteerd...'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf69396-6952-4a32-ab7e-ef3f90304aeb",
   "metadata": {},
   "source": [
    "### Initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d698270-9a70-4ec8-b173-4094b4fb92e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e0375fd43f455bbccc8f630d83f022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e843a354f4f64697ab3e5d646b8416f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2362bffcd94956b4b2290be46f9417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85a9f7f76b247388db120b84da8794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf275c3-74e5-43c4-a416-4c5a0df874ed",
   "metadata": {},
   "source": [
    "#### Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53c6d8b4-62e1-4615-b894-54ae8e6517ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69bd4ae7df74e13b4d447c741eb4fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43762de2d3714d3780fd417d193f3e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35be18538bf441bcbbbbeed7128dcfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea332c7c-f172-4a91-bd6d-719359f575d8",
   "metadata": {},
   "source": [
    "Beacuse we found that the labels are text labels (language codes like 'zh' for Chinese) rather than integer labels. We'll need to convert these text labels into integer labels for the model to work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ed94b-de63-4b29-89f9-8df7426ab654",
   "metadata": {},
   "source": [
    "### Convert text labels to integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ed4720c-b258-41ca-b292-84f2cd89726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccccd8d-a958-4682-9a74-9f5f27496f4a",
   "metadata": {},
   "source": [
    "#### Fit the label encoder on the training set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cc39810-c022-4d93-9781-36dcd912d2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(dataset['train']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3404a-4783-47bd-b5a9-4fcc440d7bfb",
   "metadata": {},
   "source": [
    "### # Apply the label encoder to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4218bac-ab97-4923-959d-b6dca2911d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985e843d74ae423b8386999f34816767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10704bac48ff42f89a5a1e11e1333cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb04f746bd3432c8673e85fd3a14fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode_labels(examples):\n",
    "    examples['labels'] = label_encoder.transform(examples['labels'])\n",
    "    return examples\n",
    "\n",
    "encoded_dataset = encoded_dataset.map(encode_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ba70c-c465-4139-b0e7-c37b53ee5887",
   "metadata": {},
   "source": [
    "### Prepare the data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbac3c3c-f853-4d55-96ed-f8b5ec593c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c404d9e-f56e-4941-9995-b57aa24eb67e",
   "metadata": {},
   "source": [
    "### Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6dd6832a-aac5-4809-a5f4-0e12eba56166",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = encoded_dataset[\"train\"]\n",
    "val_dataset = encoded_dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a927454-7072-4a7b-8992-4b9fccef1ed9",
   "metadata": {},
   "source": [
    "### Check the split dataset and encoded labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bc90895-04fe-47b1-bd53-e38d3da72e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 70000\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0774deaa-bcf2-4ae6-b526-6059b1425020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 1,\n",
       " 19,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 17,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 12,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 11,\n",
       " 2,\n",
       " 3,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 19,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 15,\n",
       " 13,\n",
       " 6,\n",
       " 12,\n",
       " 2,\n",
       " 12,\n",
       " 6,\n",
       " 6,\n",
       " 15,\n",
       " 18,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 18,\n",
       " 19,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 2,\n",
       " 0,\n",
       " 17,\n",
       " 15,\n",
       " 8,\n",
       " 19,\n",
       " 12,\n",
       " 18,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 18,\n",
       " 14,\n",
       " 16,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 3,\n",
       " 10,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 19,\n",
       " 17,\n",
       " 4,\n",
       " 15,\n",
       " 10,\n",
       " 8,\n",
       " 19,\n",
       " 7,\n",
       " 19,\n",
       " 19,\n",
       " 16,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 15,\n",
       " 18,\n",
       " 13,\n",
       " 2,\n",
       " 17,\n",
       " 2,\n",
       " 19,\n",
       " 5,\n",
       " 9,\n",
       " 19,\n",
       " 18,\n",
       " 3,\n",
       " 13,\n",
       " 18,\n",
       " 6,\n",
       " 16,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 13,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 1,\n",
       " 0,\n",
       " 17,\n",
       " 4,\n",
       " 15,\n",
       " 7,\n",
       " 11,\n",
       " 8,\n",
       " 13,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 2,\n",
       " 13,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 17,\n",
       " 5,\n",
       " 19,\n",
       " 13,\n",
       " 6,\n",
       " 15,\n",
       " 1,\n",
       " 4,\n",
       " 12,\n",
       " 18,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 16,\n",
       " 10,\n",
       " 7,\n",
       " 14,\n",
       " 8,\n",
       " 15,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 19,\n",
       " 6,\n",
       " 12,\n",
       " 16,\n",
       " 13,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 9,\n",
       " 13,\n",
       " 12,\n",
       " 5,\n",
       " 9,\n",
       " 10,\n",
       " 0,\n",
       " 12,\n",
       " 11,\n",
       " 2,\n",
       " 14,\n",
       " 10,\n",
       " 18,\n",
       " 7,\n",
       " 14,\n",
       " 13,\n",
       " 7,\n",
       " 19,\n",
       " 19,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 10,\n",
       " 17,\n",
       " 19,\n",
       " 16,\n",
       " 1,\n",
       " 12,\n",
       " 10,\n",
       " 19,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 17,\n",
       " 7,\n",
       " 12,\n",
       " 17,\n",
       " 7,\n",
       " 11,\n",
       " 10,\n",
       " 18,\n",
       " 11,\n",
       " 18,\n",
       " 18,\n",
       " 4,\n",
       " 15,\n",
       " 9,\n",
       " 5,\n",
       " 12,\n",
       " 2,\n",
       " 10,\n",
       " 3,\n",
       " 13,\n",
       " 9,\n",
       " 12,\n",
       " 6,\n",
       " 3,\n",
       " 19,\n",
       " 12,\n",
       " 2,\n",
       " 0,\n",
       " 17,\n",
       " 18,\n",
       " 1,\n",
       " 17,\n",
       " 10,\n",
       " 17,\n",
       " 14,\n",
       " 8,\n",
       " 14,\n",
       " 13,\n",
       " 19,\n",
       " 15,\n",
       " 19,\n",
       " 9,\n",
       " 18,\n",
       " 14,\n",
       " 14,\n",
       " 18,\n",
       " 18,\n",
       " 8,\n",
       " 12,\n",
       " 15,\n",
       " 4,\n",
       " 19,\n",
       " 8,\n",
       " 11,\n",
       " 12,\n",
       " 6,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 13,\n",
       " 4,\n",
       " 8,\n",
       " 12,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 16,\n",
       " 17,\n",
       " 3,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 15,\n",
       " 18,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 16,\n",
       " 14,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 19,\n",
       " 16,\n",
       " 13,\n",
       " 19,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 12,\n",
       " 17,\n",
       " 8,\n",
       " 19,\n",
       " 5,\n",
       " 9,\n",
       " 12,\n",
       " 8,\n",
       " 10,\n",
       " 14,\n",
       " 0,\n",
       " 2,\n",
       " 19,\n",
       " 2,\n",
       " 4,\n",
       " 19,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 14,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 18,\n",
       " 15,\n",
       " 15,\n",
       " 7,\n",
       " 4,\n",
       " 16,\n",
       " 14,\n",
       " 12,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 15,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 12,\n",
       " 7,\n",
       " 16,\n",
       " 8,\n",
       " 6,\n",
       " 19,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 19,\n",
       " 10,\n",
       " 4,\n",
       " 3,\n",
       " 16,\n",
       " 8,\n",
       " 12,\n",
       " 6,\n",
       " 10,\n",
       " 18,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 17,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 14,\n",
       " 16,\n",
       " 13,\n",
       " 4,\n",
       " 19,\n",
       " 13,\n",
       " 19,\n",
       " 8,\n",
       " 19,\n",
       " 9,\n",
       " 19,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 11,\n",
       " 1,\n",
       " 11,\n",
       " 12,\n",
       " 5,\n",
       " 16,\n",
       " 5,\n",
       " 5,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 11,\n",
       " 3,\n",
       " 10,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 16,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 3,\n",
       " 11,\n",
       " 13,\n",
       " 1,\n",
       " 12,\n",
       " 6,\n",
       " 11,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 12,\n",
       " 13,\n",
       " 9,\n",
       " 13,\n",
       " 8,\n",
       " 16,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 18,\n",
       " 15,\n",
       " 5,\n",
       " 14,\n",
       " 3,\n",
       " 11,\n",
       " 16,\n",
       " 17,\n",
       " 13,\n",
       " 5,\n",
       " 13,\n",
       " 14,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 11,\n",
       " 2,\n",
       " 18,\n",
       " 1,\n",
       " 8,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 19,\n",
       " 18,\n",
       " 13,\n",
       " 5,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 14,\n",
       " 9,\n",
       " 2,\n",
       " 13,\n",
       " 12,\n",
       " 10,\n",
       " 3,\n",
       " 3,\n",
       " 15,\n",
       " 6,\n",
       " 9,\n",
       " 19,\n",
       " 3,\n",
       " 4,\n",
       " 18,\n",
       " 9,\n",
       " 1,\n",
       " 11,\n",
       " 19,\n",
       " 8,\n",
       " 1,\n",
       " 11,\n",
       " 5,\n",
       " 15,\n",
       " 13,\n",
       " 18,\n",
       " 4,\n",
       " 6,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 7,\n",
       " 16,\n",
       " 10,\n",
       " 14,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 15,\n",
       " 17,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 15,\n",
       " 14,\n",
       " 8,\n",
       " 11,\n",
       " 19,\n",
       " 13,\n",
       " 17,\n",
       " 6,\n",
       " 18,\n",
       " 17,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 12,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 19,\n",
       " 13,\n",
       " 12,\n",
       " 17,\n",
       " 2,\n",
       " 13,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 15,\n",
       " 17,\n",
       " 1,\n",
       " 6,\n",
       " 12,\n",
       " 14,\n",
       " 3,\n",
       " 10,\n",
       " 12,\n",
       " 18,\n",
       " 6,\n",
       " 0,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 18,\n",
       " 8,\n",
       " 16,\n",
       " 0,\n",
       " 17,\n",
       " 2,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 12,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 14,\n",
       " 3,\n",
       " 18,\n",
       " 17,\n",
       " 1,\n",
       " 19,\n",
       " 1,\n",
       " 8,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 11,\n",
       " 6,\n",
       " 5,\n",
       " 11,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 19,\n",
       " 4,\n",
       " 18,\n",
       " 17,\n",
       " 10,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 17,\n",
       " 5,\n",
       " 16,\n",
       " 3,\n",
       " 14,\n",
       " 19,\n",
       " 13,\n",
       " 15,\n",
       " 8,\n",
       " 0,\n",
       " 15,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 19,\n",
       " 11,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 8,\n",
       " 10,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 17,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 19,\n",
       " 13,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 18,\n",
       " 5,\n",
       " 6,\n",
       " 18,\n",
       " 17,\n",
       " 10,\n",
       " 7,\n",
       " 17,\n",
       " 2,\n",
       " 5,\n",
       " 19,\n",
       " 19,\n",
       " 10,\n",
       " 2,\n",
       " 16,\n",
       " 13,\n",
       " 19,\n",
       " 1,\n",
       " 18,\n",
       " 3,\n",
       " 14,\n",
       " 10,\n",
       " 13,\n",
       " 4,\n",
       " 7,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 16,\n",
       " 17,\n",
       " 2,\n",
       " 19,\n",
       " 17,\n",
       " 15,\n",
       " 13,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 12,\n",
       " 6,\n",
       " 12,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 14,\n",
       " 12,\n",
       " 0,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 0,\n",
       " 7,\n",
       " 16,\n",
       " 0,\n",
       " 4,\n",
       " 11,\n",
       " 17,\n",
       " 6,\n",
       " 11,\n",
       " 6,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 1,\n",
       " 5,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 9,\n",
       " 12,\n",
       " 1,\n",
       " 11,\n",
       " 19,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 13,\n",
       " 7,\n",
       " 0,\n",
       " 19,\n",
       " 19,\n",
       " 2,\n",
       " 4,\n",
       " 14,\n",
       " 16,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 11,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 1,\n",
       " 6,\n",
       " 12,\n",
       " 2,\n",
       " 9,\n",
       " 15,\n",
       " 0,\n",
       " 16,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 19,\n",
       " 2,\n",
       " 6,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 16,\n",
       " 15,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 7,\n",
       " 15,\n",
       " 14,\n",
       " 2,\n",
       " 14,\n",
       " 0,\n",
       " 14,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 13,\n",
       " 14,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 17,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 14,\n",
       " 10,\n",
       " 7,\n",
       " 14,\n",
       " 13,\n",
       " 18,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 7,\n",
       " 13,\n",
       " 4,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 18,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 19,\n",
       " 1,\n",
       " 2,\n",
       " 15,\n",
       " 13,\n",
       " 4,\n",
       " 13,\n",
       " 5,\n",
       " 13,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 14,\n",
       " 0,\n",
       " 9,\n",
       " 12,\n",
       " 4,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 14,\n",
       " 19,\n",
       " 11,\n",
       " 5,\n",
       " 9,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 14,\n",
       " 19,\n",
       " 17,\n",
       " 7,\n",
       " 1,\n",
       " 13,\n",
       " 8,\n",
       " 5,\n",
       " 17,\n",
       " 3,\n",
       " 11,\n",
       " 5,\n",
       " 13,\n",
       " 13,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 13,\n",
       " 15,\n",
       " 19,\n",
       " 5,\n",
       " 15,\n",
       " 1,\n",
       " 18,\n",
       " 14,\n",
       " 19,\n",
       " 12,\n",
       " 3,\n",
       " 19,\n",
       " 12,\n",
       " 15,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 7,\n",
       " 9,\n",
       " 13,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 19,\n",
       " 7,\n",
       " 2,\n",
       " 10,\n",
       " 8,\n",
       " 1,\n",
       " 13,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 16,\n",
       " 15,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 14,\n",
       " 19,\n",
       " 2,\n",
       " 1,\n",
       " 17,\n",
       " 9,\n",
       " 19,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 11,\n",
       " 13,\n",
       " 16,\n",
       " 5,\n",
       " 5,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 16,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 17,\n",
       " 12,\n",
       " 9,\n",
       " 12,\n",
       " 17,\n",
       " 11,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 2,\n",
       " 19,\n",
       " 15,\n",
       " 4,\n",
       " 7,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 18,\n",
       " 15,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eada5f3-a45b-41aa-a712-f1b89be3f6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e624f0-f5ca-44cb-bcbf-1c886d8743f5",
   "metadata": {},
   "source": [
    "Seems we successfully encode the label and split the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95de88-4b0d-4958-99ab-4728e944d490",
   "metadata": {},
   "source": [
    "### Get the number of unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ded7eff3-807f-475b-ad0c-da894e0fcbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740d445-a2be-4e06-ad35-31a2d1dbe20c",
   "metadata": {},
   "source": [
    "### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "215a65da-70a4-4caf-8def-1b2fad145527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b33be9-c37a-4fb1-970c-8857a255a2ab",
   "metadata": {},
   "source": [
    "### Load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a341c0c-6ed5-4489-a2ff-90ffea71f31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c204351d2048af9533fe11add07094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203bb96-7b11-4202-9a39-89776794ad54",
   "metadata": {},
   "source": [
    "### Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "116562f6-7e76-4f97-859f-dae2754f054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45ddb7-d7fc-4bae-a189-e25fafec5a86",
   "metadata": {},
   "source": [
    "### Define the compute_metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3fae3b0-e445-43a4-9b99-2b17ca989471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae5893fb-e69d-4d2a-be6b-2c167f01eb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11002c1c-e40c-4ac2-befd-e68ddac6a58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize a Trainer with compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "939035f9-fb5b-47da-a62e-2afa471bfefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_with_metrics = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2f880-574d-4c9c-b635-f9c793d3e276",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a05e988-7114-412e-ba3d-02c77e8adbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26250' max='26250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26250/26250 3:16:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.057572</td>\n",
       "      <td>0.992700</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.993024</td>\n",
       "      <td>0.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.066791</td>\n",
       "      <td>0.993500</td>\n",
       "      <td>0.993528</td>\n",
       "      <td>0.993810</td>\n",
       "      <td>0.993500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.072872</td>\n",
       "      <td>0.993500</td>\n",
       "      <td>0.993531</td>\n",
       "      <td>0.993822</td>\n",
       "      <td>0.993500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26250, training_loss=0.010143891422663417, metrics={'train_runtime': 11794.8467, 'train_samples_per_second': 17.804, 'train_steps_per_second': 2.226, 'total_flos': 2.78270834688e+16, 'train_loss': 0.010143891422663417, 'epoch': 3.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_with_metrics.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d7bb5-180a-4d77-a2e1-8aae578355f9",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa2e28a4-c419-4531-8e6b-e4bfc2f57d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 02:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer_with_metrics.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e43752f-1381-4df7-9d84-ba53e9a4679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.07287164777517319, 'eval_accuracy': 0.9935, 'eval_f1': 0.9935310587705737, 'eval_precision': 0.9938219583210134, 'eval_recall': 0.9935, 'eval_runtime': 163.8783, 'eval_samples_per_second': 61.021, 'eval_steps_per_second': 7.628, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44f04dfd-b3cf-4f03-a499-91db2c95d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.07287164777517319\n",
      "Validation Accuracy: 0.9935\n",
      "Validation Precision: 0.9938219583210134\n",
      "Validation Recall: 0.9935\n",
      "Validation F1: 0.9935310587705737\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Loss: {eval_results['eval_loss']}\")\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n",
    "print(f\"Validation F1: {eval_results['eval_f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31f557-308b-4e44-ab84-9257f00e59c4",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b9f450d-93a8-4261-a894-a37f1e524f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json',\n",
       " './fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"./fine_tuned_model\"\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d7851-efb9-491b-bc65-25425a980b80",
   "metadata": {},
   "source": [
    "### Load the saved model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5a8b28c-b319-4bc3-9595-61a35dd0ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "loaded_model_q1 = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
    "loaded_tokenizer_q1 = DistilBertTokenizerFast.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92173d8a-3b5b-4991-a656-a26bd3bb64d4",
   "metadata": {},
   "source": [
    "### Example inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c612fd4-bf7a-4b80-81eb-50a56d44f0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted language for Q1: zh\n"
     ]
    }
   ],
   "source": [
    "def predict_language_q1(text):\n",
    "    inputs = loaded_tokenizer_q1(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = loaded_model_q1(**inputs).logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_id])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Example text for inference\n",
    "example_text_q1 = \"早安，你吃早餐了嗎？\"\n",
    "predicted_language_q1 = predict_language_q1(example_text_q1)\n",
    "print(f\"Predicted language for Q1: {predicted_language_q1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd956a-0563-456c-a3df-d6aff75cf5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ec64ed3-aaf2-4c96-808e-1f061e06ac3c",
   "metadata": {},
   "source": [
    "### Quesiton 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9fd3ec9-3546-4369-8fbc-97e3b521c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, TrainingArguments, Trainer, DataCollatorWithPadding, DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a7f83ee-7a72-4874-a684-638b6470a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"papluca/language-identification\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(dataset['train']['labels'])\n",
    "\n",
    "def encode_labels(examples):\n",
    "    examples['labels'] = label_encoder.transform(examples['labels'])\n",
    "    return examples\n",
    "\n",
    "encoded_dataset = encoded_dataset.map(encode_labels, batched=True)\n",
    "\n",
    "# Prepare data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset = encoded_dataset[\"train\"]\n",
    "val_dataset = encoded_dataset[\"validation\"]\n",
    "num_labels = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0e54b-33e9-448e-8629-d848d4682557",
   "metadata": {},
   "source": [
    "### Custom model for using the [SEP] Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b704534-86f0-447b-8eca-2cbd417d5090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e9ddc-73ab-4711-b4a0-a7a5c0a474c9",
   "metadata": {},
   "source": [
    "### Initialize the custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7554d34-d193-4730-afa1-89fa1a8efa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token_model = SEPTokenModel(\"distilbert-base-multilingual-cased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d4b25-07f1-4bbe-9291-dc54b3d726a0",
   "metadata": {},
   "source": [
    "### Training arguments (same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3c8f56cb-2dc3-474a-ac0b-ea920713aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_sep_token\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614f986-f11f-4d2c-a4e9-d7eda1524bdc",
   "metadata": {},
   "source": [
    "### Metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e1dba7ed-3960-4397-addd-2b4602f4344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a4b60-e35a-4378-a5ae-932585550c02",
   "metadata": {},
   "source": [
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c4e42d3-1f0c-44a9-b3eb-42786abf1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_with_sep_token = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86941e63-5788-4631-b77e-b3600b89dbd7",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "980da42d-92cc-46ee-a005-bcea1fb63805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26250' max='26250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26250/26250 3:06:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.056515</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>0.993432</td>\n",
       "      <td>0.993732</td>\n",
       "      <td>0.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.064906</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.994018</td>\n",
       "      <td>0.994264</td>\n",
       "      <td>0.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.064295</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>0.993818</td>\n",
       "      <td>0.994055</td>\n",
       "      <td>0.993800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26250, training_loss=0.020685963184989633, metrics={'train_runtime': 11177.0799, 'train_samples_per_second': 18.788, 'train_steps_per_second': 2.349, 'total_flos': 2.764987008329568e+16, 'train_loss': 0.020685963184989633, 'epoch': 3.0})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_with_sep_token.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f7e93-0468-4d18-b1e6-c3cf1b5fa177",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0a0bc798-70ab-40f0-a26d-66488146f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results_sep_token = trainer_with_sep_token.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "319a35be-4e7d-4ff1-a71b-49672541a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results with [SEP] token: {'eval_loss': 0.06490599364042282, 'eval_accuracy': 0.994, 'eval_f1': 0.9940175466934492, 'eval_precision': 0.9942640919760731, 'eval_recall': 0.994, 'eval_runtime': 122.769, 'eval_samples_per_second': 81.454, 'eval_steps_per_second': 10.182, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Evaluation results with [SEP] token: {eval_results_sep_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4a8b872e-d6b5-4098-8b82-5ebc78850e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.06490599364042282\n",
      "Validation Accuracy: 0.994\n",
      "Validation Precision: 0.9942640919760731\n",
      "Validation Recall: 0.994\n",
      "Validation F1: 0.9940175466934492\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Loss: {eval_results_sep_token['eval_loss']}\")\n",
    "print(f\"Validation Accuracy: {eval_results_sep_token['eval_accuracy']}\")\n",
    "print(f\"Validation Precision: {eval_results_sep_token['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results_sep_token['eval_recall']}\")\n",
    "print(f\"Validation F1: {eval_results_sep_token['eval_f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50665165-c355-4ac9-a68c-7a66648eed60",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4dd3eb1d-e468-4bda-aa06-3bfb61f521d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_sep_token_model/tokenizer_config.json',\n",
       " './fine_tuned_sep_token_model/special_tokens_map.json',\n",
       " './fine_tuned_sep_token_model/vocab.txt',\n",
       " './fine_tuned_sep_token_model/added_tokens.json',\n",
       " './fine_tuned_sep_token_model/tokenizer.json')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir_sep = \"./fine_tuned_sep_token_model\"\n",
    "model.save_pretrained(model_dir_sep)\n",
    "tokenizer.save_pretrained(model_dir_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4770d9-2f45-41e6-a8c0-23a23c362148",
   "metadata": {},
   "source": [
    "### Load the saved model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "561f0c50-8f13-4658-a9a5-5b2354f08958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "loaded_model_q2 = AutoModelForSequenceClassification.from_pretrained(model_dir_sep, num_labels=num_labels)\n",
    "loaded_tokenizer_q2 = AutoTokenizer.from_pretrained(model_dir_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b548bd-a65e-4ed4-95ae-8e829cfa145e",
   "metadata": {},
   "source": [
    "### Example inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a8ed5414-27cf-4b4e-978e-67462c16ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language_q2_simple(text):\n",
    "    inputs = loaded_tokenizer_q2(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model_q2(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_class_id])\n",
    "        return predicted_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8c47d490-f469-4546-82d3-76d9a7d18b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted language for Q2: fr\n"
     ]
    }
   ],
   "source": [
    "# Example text for inference\n",
    "example_text_q2 = \"Bonjour, comment allez-vous?\"\n",
    "predicted_language_q2_simple = predict_language_q2_simple(example_text_q2)\n",
    "print(f\"Predicted language for Q2: {predicted_language_q2_simple}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a6825f2d-7850-4b16-91a9-2eb29da49370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Evaluation Metrics:\n",
      "=================================\n",
      "Metrics with [CLS] token:\n",
      "Accuracy: 0.9935\n",
      "F1-score: 0.9935\n",
      "Precision: 0.9938\n",
      "Recall: 0.9935\n",
      "\n",
      "Metrics with [SEP] token:\n",
      "Accuracy: 0.9940\n",
      "F1-score: 0.9940\n",
      "Precision: 0.9943\n",
      "Recall: 0.9940\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of Evaluation Metrics:\")\n",
    "print(\"=================================\")\n",
    "\n",
    "print(\"Metrics with [CLS] token:\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-score: {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {eval_results['eval_recall']:.4f}\")\n",
    "\n",
    "print(\"\\nMetrics with [SEP] token:\")\n",
    "print(f\"Accuracy: {eval_results_sep_token['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-score: {eval_results_sep_token['eval_f1']:.4f}\")\n",
    "print(f\"Precision: {eval_results_sep_token['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {eval_results_sep_token['eval_recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020f93d-4906-4413-833c-c83b2170a945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace7dd9d-87fb-4864-a26d-70bdf2145b52",
   "metadata": {},
   "source": [
    "* **Accuracy:** The model achieved an accuracy of 0.9940 with the [SEP] token, which is marginally higher than the 0.9935 accuracy obtained with the [CLS] token.\n",
    "* **F1-score:** Similarly, the F1-score with the [SEP] token was 0.9940, compared to 0.9935 with the [CLS] token.\n",
    "* **Precision and Recall:** Both precision and recall were higher with the [SEP] token, at 0.9943 and 0.9940 respectively, compared to 0.9938 and 0.9935 with the [CLS] token.\n",
    "\n",
    "Additionally, the model evaluated with the [SEP] token exhibited a lower loss (0.0649) compared to the [CLS] token (0.0729), indicating better overall performance. The evaluation runtime was also shorter for the [SEP] token, processing samples and steps at a faster rate.\n",
    "The slight improvements in accuracy, F1-score, precision, and recall, along with the lower evaluation loss and faster runtime, demonstrate that utilizing the [SEP] token for embedding yields better performance for the language identification task. This suggests that the [SEP] token captures relevant information more effectively for this particular model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a29972-6a0c-4cd8-9b39-08b910d4eeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03519113-5067-4d8e-a7f4-d9ef5300496c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e826ca9-2a1b-4e57-8659-3379524e6802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2873360-4c05-4b3c-b749-2870a62e6fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
