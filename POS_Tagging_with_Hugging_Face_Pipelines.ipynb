{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00be4faf-2657-4b33-9a16-a76ff668c156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available, otherwise CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5968d423-014e-4bfd-a15f-8ee21e8dce2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 24 16:30:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   69C    P0             30W /   70W |   14907MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a4cd6b-6090-4538-8c76-ff85bf683da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b4ec1-2869-4d40-808d-f48f13180943",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4826165a-f9bd-4ed4-8b5b-38d92b18881f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8fc53-bac5-429d-9bba-62fdb58345fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8e97d33-13ae-43fa-b20f-c55361658452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "name = \"TweebankNLP/bertweet-tb2_ewt-pos-tagging\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c9305-412a-47bc-8036-f7775e0ad68a",
   "metadata": {},
   "source": [
    "* **AutoTokenizer:** Loads the tokenizer specific to the model.\n",
    "* **AutoModelForTokenClassification:** Loads the model fine-tuned for token classification tasks, such as POS tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16beb28-da10-451c-bf1f-86883511eacd",
   "metadata": {},
   "source": [
    "### 3. Initialize the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4a04b49-c181-482a-a438-fe2a2cdc5dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use CPU\n",
    "device = -1  # CPU device ID\n",
    "\n",
    "# Initialize the pipeline for token classification\n",
    "pos_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559545e1-46f9-445b-8e8a-8da7608a68c7",
   "metadata": {},
   "source": [
    "* **pipeline:** Initializes a pipeline for named entity recognition (NER) which is used here for POS tagging. The aggregation_strategy=\"simple\" helps to merge subwords into full words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00769ea-054f-44d2-99a4-401081fd1a31",
   "metadata": {},
   "source": [
    "### 4. Define Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6974b-a279-4f75-822f-200e0c6cc57b",
   "metadata": {},
   "source": [
    "a. Function to Get POS Sequence\n",
    "\n",
    "get_pos_sequence: Processes the output of the pipeline to merge subword tokens into full words and collects their POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36790aab-2a56-4376-84c3-8ba92865bd40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pos_sequence(tags):\n",
    "    pos_sequence = []\n",
    "    current_word = \"\"\n",
    "    current_pos = None\n",
    "    for tag in tags:\n",
    "        token = tag['word']\n",
    "        pos_tag = tag['entity_group']\n",
    "        \n",
    "        if token.startswith(\"##\"):  # Handle subword tokens\n",
    "            current_word += token[2:]\n",
    "        else:\n",
    "            if current_word:\n",
    "                pos_sequence.append((current_word, current_pos))\n",
    "            current_word = token\n",
    "            current_pos = pos_tag\n",
    "    \n",
    "    if current_word:  # Append the last word if any\n",
    "        pos_sequence.append((current_word, current_pos))\n",
    "        \n",
    "    return pos_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a586309-f52d-410e-bbfd-ff12747a1c88",
   "metadata": {},
   "source": [
    "b. Function to Summarize POS Tags\n",
    "\n",
    "get_pos_summary: Creates a summary of the POS tags by counting the occurrence of each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ba1c412-018c-4ca1-9bac-2a7bee7cada5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pos_summary(tags):\n",
    "    pos_tags = {}\n",
    "    for tag in tags:\n",
    "        pos_tag = tag['entity_group']\n",
    "        if pos_tag in pos_tags:\n",
    "            pos_tags[pos_tag] += 1\n",
    "        else:\n",
    "            pos_tags[pos_tag] = 1\n",
    "    return pos_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18309d-3511-4418-beff-1a458687d193",
   "metadata": {},
   "source": [
    "c. Function to Apply POS Tagging\n",
    "\n",
    "get_token_pos_data: Applies the POS tagging pipeline to the text and returns both the sequence of POS tags and the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "977648a3-5878-4c4a-a484-ae089d7328c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_pos_data(text):\n",
    "    tags = pos_pipeline(text)\n",
    "    pos_sequence = get_pos_sequence(tags)\n",
    "    pos_summary = get_pos_summary(tags)\n",
    "    return pos_sequence, pos_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30dd7b-4891-42d9-a3e5-f85dbeae0956",
   "metadata": {},
   "source": [
    "### 5. Apply POS Tagging to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8a37c1d-746e-4f9e-b8e5-70ec7d5db100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>pos_tokens_sequence</th>\n",
       "      <th>pos_tokens_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>[(the, DET), (quick brown, ADJ), (fox, NOUN), (jumps, VERB), (over, ADP), (the, DET), (lazy, ADJ), (dog, NOUN), (., PUNCT)]</td>\n",
       "      <td>{'DET': 2, 'ADJ': 2, 'NOUN': 2, 'VERB': 1, 'ADP': 1, 'PUNCT': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Although it was raining heavily, the children went outside to play soccer.</td>\n",
       "      <td>[(although, SCONJ), (it, PRON), (was, AUX), (raining, VERB), (heavily, ADV), (,, PUNCT), (the, DET), (children, NOUN), (went, VERB), (outside, ADV), (to, PART), (play, VERB), (soccer, NOUN), (., PUNCT)]</td>\n",
       "      <td>{'SCONJ': 1, 'PRON': 1, 'AUX': 1, 'VERB': 3, 'ADV': 2, 'PUNCT': 2, 'DET': 1, 'NOUN': 2, 'PART': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What time does the meeting start tomorrow?</td>\n",
       "      <td>[(what, DET), (time, NOUN), (does, AUX), (the, DET), (meeting, NOUN), (start, VERB), (tomorrow, NOUN), (?, PUNCT)]</td>\n",
       "      <td>{'DET': 2, 'NOUN': 3, 'AUX': 1, 'VERB': 1, 'PUNCT': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanted to go to the concert, but I had to work late.</td>\n",
       "      <td>[(i, PRON), (wanted, VERB), (to, PART), (go, VERB), (to, ADP), (the, DET), (concert, NOUN), (,, PUNCT), (but, CCONJ), (i, PRON), (had, VERB), (to, PART), (work, VERB), (late, ADV), (., PUNCT)]</td>\n",
       "      <td>{'PRON': 2, 'VERB': 4, 'PART': 2, 'ADP': 1, 'DET': 1, 'NOUN': 1, 'PUNCT': 2, 'CCONJ': 1, 'ADV': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow, what an incredible performance that was!</td>\n",
       "      <td>[(wow, INTJ), (,, PUNCT), (what an, DET), (incredible, ADJ), (performance, NOUN), (that, PRON), (was, AUX), (!, PUNCT)]</td>\n",
       "      <td>{'INTJ': 1, 'PUNCT': 2, 'DET': 1, 'ADJ': 1, 'NOUN': 1, 'PRON': 1, 'AUX': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The tall, handsome man with the blue jacket and the red hat greeted everyone warmly.</td>\n",
       "      <td>[(the, DET), (tall, ADJ), (,, PUNCT), (handsome, ADJ), (man, NOUN), (with, ADP), (the, DET), (blue, ADJ), (jacket, NOUN), (and, CCONJ), (the, DET), (red, ADJ), (hat, NOUN), (greeted, VERB), (everyone, PRON), (warmly, ADV), (., PUNCT)]</td>\n",
       "      <td>{'DET': 3, 'ADJ': 4, 'PUNCT': 2, 'NOUN': 3, 'ADP': 1, 'CCONJ': 1, 'VERB': 1, 'PRON': 1, 'ADV': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>She didn't go to the party because she was feeling sick, and her friends understood why.</td>\n",
       "      <td>[(she, PRON), (didn, AUX), (', PUNCT), (t, PART), (go, VERB), (to, ADP), (the, DET), (party, NOUN), (because, SCONJ), (she, PRON), (was, AUX), (feeling, VERB), (sick, ADJ), (,, PUNCT), (and, CCONJ), (her, PRON), (friends, NOUN), (understood, VERB), (why, ADV), (., PUNCT)]</td>\n",
       "      <td>{'PRON': 3, 'AUX': 2, 'PUNCT': 3, 'PART': 1, 'VERB': 3, 'ADP': 1, 'DET': 1, 'NOUN': 2, 'SCONJ': 1, 'ADJ': 1, 'CCONJ': 1, 'ADV': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carefully review the report and ensure that all errors are corrected promptly.</td>\n",
       "      <td>[(carefully, ADV), (review, VERB), (the, DET), (report, NOUN), (and, CCONJ), (ensure, VERB), (that, SCONJ), (all, DET), (errors, NOUN), (are, AUX), (corrected, VERB), (promptly, ADV), (., PUNCT)]</td>\n",
       "      <td>{'ADV': 2, 'VERB': 3, 'DET': 2, 'NOUN': 2, 'CCONJ': 1, 'SCONJ': 1, 'AUX': 1, 'PUNCT': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The neural network's performance improved significantly after tuning the hyperparameters.</td>\n",
       "      <td>[(the, DET), (neural, ADJ), (network, NOUN), (' s, PART), (performance, NOUN), (improved, VERB), (significantly, ADV), (after, SCONJ), (tuning, VERB), (the, DET), (hyperparameters, NOUN), (., PUNCT)]</td>\n",
       "      <td>{'DET': 2, 'ADJ': 1, 'NOUN': 3, 'PART': 1, 'VERB': 2, 'ADV': 1, 'SCONJ': 1, 'PUNCT': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>He hit the nail on the head with his comments about the project's issues.</td>\n",
       "      <td>[(he, PRON), (hit, VERB), (the, DET), (nail, NOUN), (on, ADP), (the, DET), (head, NOUN), (with, ADP), (his, PRON), (comments, NOUN), (about, ADP), (the, DET), (project, NOUN), (' s, PART), (issues, NOUN), (., PUNCT)]</td>\n",
       "      <td>{'PRON': 2, 'VERB': 1, 'DET': 3, 'NOUN': 5, 'ADP': 3, 'PART': 1, 'PUNCT': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    comments  \\\n",
       "0                                               The quick brown fox jumps over the lazy dog.   \n",
       "1                 Although it was raining heavily, the children went outside to play soccer.   \n",
       "2                                                 What time does the meeting start tomorrow?   \n",
       "3                                     I wanted to go to the concert, but I had to work late.   \n",
       "4                                              Wow, what an incredible performance that was!   \n",
       "5       The tall, handsome man with the blue jacket and the red hat greeted everyone warmly.   \n",
       "6   She didn't go to the party because she was feeling sick, and her friends understood why.   \n",
       "7             Carefully review the report and ensure that all errors are corrected promptly.   \n",
       "8  The neural network's performance improved significantly after tuning the hyperparameters.   \n",
       "9                  He hit the nail on the head with his comments about the project's issues.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                pos_tokens_sequence  \\\n",
       "0                                                                                                                                                       [(the, DET), (quick brown, ADJ), (fox, NOUN), (jumps, VERB), (over, ADP), (the, DET), (lazy, ADJ), (dog, NOUN), (., PUNCT)]   \n",
       "1                                                                        [(although, SCONJ), (it, PRON), (was, AUX), (raining, VERB), (heavily, ADV), (,, PUNCT), (the, DET), (children, NOUN), (went, VERB), (outside, ADV), (to, PART), (play, VERB), (soccer, NOUN), (., PUNCT)]   \n",
       "2                                                                                                                                                                [(what, DET), (time, NOUN), (does, AUX), (the, DET), (meeting, NOUN), (start, VERB), (tomorrow, NOUN), (?, PUNCT)]   \n",
       "3                                                                                  [(i, PRON), (wanted, VERB), (to, PART), (go, VERB), (to, ADP), (the, DET), (concert, NOUN), (,, PUNCT), (but, CCONJ), (i, PRON), (had, VERB), (to, PART), (work, VERB), (late, ADV), (., PUNCT)]   \n",
       "4                                                                                                                                                           [(wow, INTJ), (,, PUNCT), (what an, DET), (incredible, ADJ), (performance, NOUN), (that, PRON), (was, AUX), (!, PUNCT)]   \n",
       "5                                        [(the, DET), (tall, ADJ), (,, PUNCT), (handsome, ADJ), (man, NOUN), (with, ADP), (the, DET), (blue, ADJ), (jacket, NOUN), (and, CCONJ), (the, DET), (red, ADJ), (hat, NOUN), (greeted, VERB), (everyone, PRON), (warmly, ADV), (., PUNCT)]   \n",
       "6  [(she, PRON), (didn, AUX), (', PUNCT), (t, PART), (go, VERB), (to, ADP), (the, DET), (party, NOUN), (because, SCONJ), (she, PRON), (was, AUX), (feeling, VERB), (sick, ADJ), (,, PUNCT), (and, CCONJ), (her, PRON), (friends, NOUN), (understood, VERB), (why, ADV), (., PUNCT)]   \n",
       "7                                                                               [(carefully, ADV), (review, VERB), (the, DET), (report, NOUN), (and, CCONJ), (ensure, VERB), (that, SCONJ), (all, DET), (errors, NOUN), (are, AUX), (corrected, VERB), (promptly, ADV), (., PUNCT)]   \n",
       "8                                                                           [(the, DET), (neural, ADJ), (network, NOUN), (' s, PART), (performance, NOUN), (improved, VERB), (significantly, ADV), (after, SCONJ), (tuning, VERB), (the, DET), (hyperparameters, NOUN), (., PUNCT)]   \n",
       "9                                                          [(he, PRON), (hit, VERB), (the, DET), (nail, NOUN), (on, ADP), (the, DET), (head, NOUN), (with, ADP), (his, PRON), (comments, NOUN), (about, ADP), (the, DET), (project, NOUN), (' s, PART), (issues, NOUN), (., PUNCT)]   \n",
       "\n",
       "                                                                                                                   pos_tokens_summary  \n",
       "0                                                                    {'DET': 2, 'ADJ': 2, 'NOUN': 2, 'VERB': 1, 'ADP': 1, 'PUNCT': 1}  \n",
       "1                                  {'SCONJ': 1, 'PRON': 1, 'AUX': 1, 'VERB': 3, 'ADV': 2, 'PUNCT': 2, 'DET': 1, 'NOUN': 2, 'PART': 1}  \n",
       "2                                                                              {'DET': 2, 'NOUN': 3, 'AUX': 1, 'VERB': 1, 'PUNCT': 1}  \n",
       "3                                  {'PRON': 2, 'VERB': 4, 'PART': 2, 'ADP': 1, 'DET': 1, 'NOUN': 1, 'PUNCT': 2, 'CCONJ': 1, 'ADV': 1}  \n",
       "4                                                         {'INTJ': 1, 'PUNCT': 2, 'DET': 1, 'ADJ': 1, 'NOUN': 1, 'PRON': 1, 'AUX': 1}  \n",
       "5                                   {'DET': 3, 'ADJ': 4, 'PUNCT': 2, 'NOUN': 3, 'ADP': 1, 'CCONJ': 1, 'VERB': 1, 'PRON': 1, 'ADV': 1}  \n",
       "6  {'PRON': 3, 'AUX': 2, 'PUNCT': 3, 'PART': 1, 'VERB': 3, 'ADP': 1, 'DET': 1, 'NOUN': 2, 'SCONJ': 1, 'ADJ': 1, 'CCONJ': 1, 'ADV': 1}  \n",
       "7                                            {'ADV': 2, 'VERB': 3, 'DET': 2, 'NOUN': 2, 'CCONJ': 1, 'SCONJ': 1, 'AUX': 1, 'PUNCT': 1}  \n",
       "8                                             {'DET': 2, 'ADJ': 1, 'NOUN': 3, 'PART': 1, 'VERB': 2, 'ADV': 1, 'SCONJ': 1, 'PUNCT': 1}  \n",
       "9                                                        {'PRON': 2, 'VERB': 1, 'DET': 3, 'NOUN': 5, 'ADP': 3, 'PART': 1, 'PUNCT': 1}  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage with a sample DataFrame\n",
    "data = {\n",
    "    \"comments\": [\n",
    "        \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"Although it was raining heavily, the children went outside to play soccer.\",\n",
    "        \"What time does the meeting start tomorrow?\",\n",
    "        \"I wanted to go to the concert, but I had to work late.\",\n",
    "        \"Wow, what an incredible performance that was!\",\n",
    "        \"The tall, handsome man with the blue jacket and the red hat greeted everyone warmly.\",\n",
    "        \"She didn't go to the party because she was feeling sick, and her friends understood why.\",\n",
    "        \"Carefully review the report and ensure that all errors are corrected promptly.\",\n",
    "        \"The neural network's performance improved significantly after tuning the hyperparameters.\",\n",
    "        \"He hit the nail on the head with his comments about the project's issues.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the POS tagging sequence and summary to DataFrame\n",
    "df['pos_tokens_sequence'], df['pos_tokens_summary'] = zip(*df['comments'].apply(get_token_pos_data))\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None)  # Display full content of each column\n",
    "\n",
    "# Display DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82d2e9c-03b8-4a1d-8fd3-f7a737e6c425",
   "metadata": {},
   "source": [
    "The output is a DataFrame showing the original comments, the sequence of POS-tagged words, and a summary of the POS tags for each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f59702-89a8-40f5-bcfa-8802bd09bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e759ee1-a2f8-4020-93a9-26fe06f09e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c755328-91ed-43f4-a933-c0575880b63b",
   "metadata": {},
   "source": [
    "### Script for POS Tagging Using vblagoje/bert-english-uncased-finetuned-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03db14a5-6c49-4762-9018-8c3314d5c064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "POS Tags:\n",
      "  the -> DET (Score: 0.9994)\n",
      "  quick brown -> ADJ (Score: 0.9697)\n",
      "  fox -> NOUN (Score: 0.9970)\n",
      "  jumps -> VERB (Score: 0.9994)\n",
      "  over -> ADP (Score: 0.9993)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  lazy -> ADJ (Score: 0.9979)\n",
      "  dog -> NOUN (Score: 0.9989)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: Although it was raining heavily, the children went outside to play soccer.\n",
      "POS Tags:\n",
      "  although -> SCONJ (Score: 0.9988)\n",
      "  it -> PRON (Score: 0.9995)\n",
      "  was -> AUX (Score: 0.9985)\n",
      "  raining -> VERB (Score: 0.9967)\n",
      "  heavily -> ADV (Score: 0.9991)\n",
      "  , -> PUNCT (Score: 0.9997)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  children -> NOUN (Score: 0.9987)\n",
      "  went -> VERB (Score: 0.9995)\n",
      "  outside -> ADV (Score: 0.9975)\n",
      "  to -> PART (Score: 0.9991)\n",
      "  play -> VERB (Score: 0.9995)\n",
      "  soccer -> NOUN (Score: 0.9892)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: What time does the meeting start tomorrow?\n",
      "POS Tags:\n",
      "  what -> DET (Score: 0.9990)\n",
      "  time -> NOUN (Score: 0.9992)\n",
      "  does -> AUX (Score: 0.9983)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  meeting -> NOUN (Score: 0.9990)\n",
      "  start -> VERB (Score: 0.9992)\n",
      "  tomorrow -> NOUN (Score: 0.9988)\n",
      "  ? -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: I wanted to go to the concert, but I had to work late.\n",
      "POS Tags:\n",
      "  i -> PRON (Score: 0.9996)\n",
      "  wanted -> VERB (Score: 0.9994)\n",
      "  to -> PART (Score: 0.9993)\n",
      "  go -> VERB (Score: 0.9995)\n",
      "  to -> ADP (Score: 0.9989)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  concert -> NOUN (Score: 0.9989)\n",
      "  , -> PUNCT (Score: 0.9997)\n",
      "  but -> CCONJ (Score: 0.9986)\n",
      "  i -> PRON (Score: 0.9996)\n",
      "  had -> VERB (Score: 0.9991)\n",
      "  to -> PART (Score: 0.9993)\n",
      "  work -> VERB (Score: 0.9990)\n",
      "  late -> ADV (Score: 0.9973)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: Wow, what an incredible performance that was!\n",
      "POS Tags:\n",
      "  wow -> INTJ (Score: 0.9957)\n",
      "  , -> PUNCT (Score: 0.9996)\n",
      "  what an -> DET (Score: 0.9253)\n",
      "  incredible -> ADJ (Score: 0.9988)\n",
      "  performance -> NOUN (Score: 0.9982)\n",
      "  that -> PRON (Score: 0.9991)\n",
      "  was -> AUX (Score: 0.6697)\n",
      "  ! -> PUNCT (Score: 0.9996)\n",
      "\n",
      "\n",
      "Sentence: The tall, handsome man with the blue jacket and the red hat greeted everyone warmly.\n",
      "POS Tags:\n",
      "  the -> DET (Score: 0.9995)\n",
      "  tall -> ADJ (Score: 0.9981)\n",
      "  , -> PUNCT (Score: 0.9997)\n",
      "  handsome -> ADJ (Score: 0.9982)\n",
      "  man -> NOUN (Score: 0.9964)\n",
      "  with -> ADP (Score: 0.9949)\n",
      "  the -> DET (Score: 0.9994)\n",
      "  blue -> ADJ (Score: 0.9914)\n",
      "  jacket -> NOUN (Score: 0.9980)\n",
      "  and -> CCONJ (Score: 0.9985)\n",
      "  the -> DET (Score: 0.9994)\n",
      "  red -> ADJ (Score: 0.9977)\n",
      "  hat -> NOUN (Score: 0.9982)\n",
      "  greeted -> VERB (Score: 0.9995)\n",
      "  everyone -> PRON (Score: 0.9983)\n",
      "  warmly -> ADV (Score: 0.9991)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: She didn't go to the party because she was feeling sick, and her friends understood why.\n",
      "POS Tags:\n",
      "  she -> PRON (Score: 0.9995)\n",
      "  didn -> AUX (Score: 0.9956)\n",
      "  ' -> PUNCT (Score: 0.9996)\n",
      "  t -> PART (Score: 0.9990)\n",
      "  go -> VERB (Score: 0.9996)\n",
      "  to -> ADP (Score: 0.9991)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  party -> NOUN (Score: 0.9992)\n",
      "  because -> SCONJ (Score: 0.9984)\n",
      "  she -> PRON (Score: 0.9995)\n",
      "  was -> AUX (Score: 0.9975)\n",
      "  feeling -> VERB (Score: 0.9992)\n",
      "  sick -> ADJ (Score: 0.9968)\n",
      "  , -> PUNCT (Score: 0.9997)\n",
      "  and -> CCONJ (Score: 0.9992)\n",
      "  her -> PRON (Score: 0.9994)\n",
      "  friends -> NOUN (Score: 0.9988)\n",
      "  understood -> VERB (Score: 0.9995)\n",
      "  why -> ADV (Score: 0.9987)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: Carefully review the report and ensure that all errors are corrected promptly.\n",
      "POS Tags:\n",
      "  carefully -> ADV (Score: 0.9993)\n",
      "  review -> VERB (Score: 0.9995)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  report -> NOUN (Score: 0.9992)\n",
      "  and -> CCONJ (Score: 0.9992)\n",
      "  ensure -> VERB (Score: 0.9994)\n",
      "  that -> SCONJ (Score: 0.9984)\n",
      "  all -> DET (Score: 0.9993)\n",
      "  errors -> NOUN (Score: 0.9991)\n",
      "  are -> AUX (Score: 0.9964)\n",
      "  corrected -> VERB (Score: 0.9992)\n",
      "  promptly -> ADV (Score: 0.9993)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: The neural network's performance improved significantly after tuning the hyperparameters.\n",
      "POS Tags:\n",
      "  the -> DET (Score: 0.9995)\n",
      "  neural -> ADJ (Score: 0.7815)\n",
      "  network -> NOUN (Score: 0.9985)\n",
      "  ' s -> PART (Score: 0.9981)\n",
      "  performance -> NOUN (Score: 0.9975)\n",
      "  improved -> VERB (Score: 0.9993)\n",
      "  significantly -> ADV (Score: 0.9992)\n",
      "  after -> SCONJ (Score: 0.9977)\n",
      "  tuning -> VERB (Score: 0.9991)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  hyperparameters -> NOUN (Score: 0.9978)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n",
      "Sentence: He hit the nail on the head with his comments about the project's issues.\n",
      "POS Tags:\n",
      "  he -> PRON (Score: 0.9995)\n",
      "  hit -> VERB (Score: 0.9995)\n",
      "  the -> DET (Score: 0.9996)\n",
      "  nail -> NOUN (Score: 0.9989)\n",
      "  on -> ADP (Score: 0.9991)\n",
      "  the -> DET (Score: 0.9995)\n",
      "  head -> NOUN (Score: 0.9989)\n",
      "  with -> ADP (Score: 0.9984)\n",
      "  his -> PRON (Score: 0.9995)\n",
      "  comments -> NOUN (Score: 0.9989)\n",
      "  about -> ADP (Score: 0.9993)\n",
      "  the -> DET (Score: 0.9996)\n",
      "  project -> NOUN (Score: 0.9992)\n",
      "  ' s -> PART (Score: 0.9980)\n",
      "  issues -> NOUN (Score: 0.9993)\n",
      "  . -> PUNCT (Score: 0.9997)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pipeline for POS tagging\n",
    "pos_pipeline = pipeline(\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\", aggregation_strategy=\"simple\")\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Although it was raining heavily, the children went outside to play soccer.\",\n",
    "    \"What time does the meeting start tomorrow?\",\n",
    "    \"I wanted to go to the concert, but I had to work late.\",\n",
    "    \"Wow, what an incredible performance that was!\",\n",
    "    \"The tall, handsome man with the blue jacket and the red hat greeted everyone warmly.\",\n",
    "    \"She didn't go to the party because she was feeling sick, and her friends understood why.\",\n",
    "    \"Carefully review the report and ensure that all errors are corrected promptly.\",\n",
    "    \"The neural network's performance improved significantly after tuning the hyperparameters.\",\n",
    "    \"He hit the nail on the head with his comments about the project's issues.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Apply the POS tagging pipeline to each sentence\n",
    "for sentence in sentences:\n",
    "    pos_tags = pos_pipeline(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(\"POS Tags:\")\n",
    "    for tag in pos_tags:\n",
    "        print(f\"  {tag['word']} -> {tag['entity_group']} (Score: {tag['score']:.4f})\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aaf6cd-4c0b-4400-9b54-69bb351a1569",
   "metadata": {},
   "source": [
    "The first method aggregates tokens into sequences and provides a summary of POS tags. It lists POS tags in a simpler format without confidence scores and provides a summary count of each tag.\n",
    "\n",
    "The second method includes each tokenâ€™s POS tag along with a confidence score. It also shows POS tags for each token individually, with additional details on confidence.\n",
    "\n",
    "Although the presentation and detail differ, the fundamental POS tags are consistent between the two outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db0565-55b5-4cc7-b52c-03128f57a0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
